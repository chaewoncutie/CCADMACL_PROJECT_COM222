{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\ella\\anaconda3\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\ella\\anaconda3\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\ella\\anaconda3\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\ella\\anaconda3\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: seaborn in c:\\users\\ella\\anaconda3\\lib\\site-packages (0.13.2)\n",
            "Requirement already satisfied: scipy in c:\\users\\ella\\anaconda3\\lib\\site-packages (1.15.2)\n",
            "Requirement already satisfied: wordcloud in c:\\users\\ella\\anaconda3\\lib\\site-packages (1.9.4)\n",
            "Requirement already satisfied: ipywidgets in c:\\users\\ella\\anaconda3\\lib\\site-packages (8.1.5)\n",
            "Requirement already satisfied: umap-learn in c:\\users\\ella\\anaconda3\\lib\\site-packages (0.5.7)\n",
            "Requirement already satisfied: hdbscan in c:\\users\\ella\\anaconda3\\lib\\site-packages (0.8.40)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: click in c:\\users\\ella\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in c:\\users\\ella\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: comm>=0.1.3 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.1)\n",
            "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipywidgets) (8.27.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
            "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: numba>=0.51.2 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: decorator in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
            "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
            "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
            "Requirement already satisfied: stack-data in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\ella\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\ella\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\ella\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
            "Requirement already satisfied: executing in c:\\users\\ella\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
            "Requirement already satisfied: asttokens in c:\\users\\ella\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
            "Requirement already satisfied: pure-eval in c:\\users\\ella\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary packages\n",
        "! pip install -U scikit-learn nltk pandas matplotlib seaborn scipy wordcloud ipywidgets umap-learn hdbscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "x_ntC4VxwK7V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import umap\n",
        "import hdbscan\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of rows in original dataset: 209527\n",
            "Number of columns in original dataset: 6\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>headline</th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>authors</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Health experts said it is too early to predict...</td>\n",
              "      <td>Carla K. Johnson, AP</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>He was subdued by passengers and crew when he ...</td>\n",
              "      <td>Mary Papenfuss</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>\"Until you have a dog you don't understand wha...</td>\n",
              "      <td>Elyse Wanshel</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
              "      <td>Caroline Bologna</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
              "      <td>Nina Golgowski</td>\n",
              "      <td>2022-09-22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  \\\n",
              "0  https://www.huffpost.com/entry/covid-boosters-...   \n",
              "1  https://www.huffpost.com/entry/american-airlin...   \n",
              "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
              "3  https://www.huffpost.com/entry/funniest-parent...   \n",
              "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
              "\n",
              "                                            headline   category  \\\n",
              "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
              "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
              "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
              "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
              "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
              "\n",
              "                                   short_description               authors  \\\n",
              "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
              "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
              "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
              "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
              "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
              "\n",
              "        date  \n",
              "0 2022-09-23  \n",
              "1 2022-09-23  \n",
              "2 2022-09-23  \n",
              "3 2022-09-23  \n",
              "4 2022-09-22  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Ella\\AppData\\Local\\Temp\\ipykernel_5316\\3045329989.py:13: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: None if isinstance(x, str) and x.strip() == '' else x.strip() if isinstance(x, str) else x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null values in each column:\n",
            "link                     0\n",
            "headline                 6\n",
            "category                 0\n",
            "short_description    19712\n",
            "authors              37418\n",
            "date                     0\n",
            "dtype: int64\n",
            "Number of duplicated rows: 13\n",
            "Number of rows after cleaning: 47010\n",
            "Number of columns after cleaning: 6\n",
            "['U.S. NEWS' 'COMEDY' 'PARENTING' 'WORLD NEWS' 'CULTURE & ARTS' 'TECH'\n",
            " 'SPORTS' 'ENTERTAINMENT' 'POLITICS' 'WEIRD NEWS' 'ENVIRONMENT'\n",
            " 'EDUCATION' 'CRIME' 'SCIENCE' 'WELLNESS' 'BUSINESS' 'STYLE & BEAUTY'\n",
            " 'FOOD & DRINK' 'MEDIA' 'QUEER VOICES' 'HOME & LIVING' 'WOMEN'\n",
            " 'BLACK VOICES' 'TRAVEL' 'MONEY' 'RELIGION' 'LATINO VOICES' 'IMPACT'\n",
            " 'WEDDINGS' 'COLLEGE' 'PARENTS' 'ARTS & CULTURE' 'STYLE' 'GREEN' 'TASTE'\n",
            " 'HEALTHY LIVING' 'THE WORLDPOST' 'GOOD NEWS' 'WORLDPOST']\n",
            "category\n",
            "POLITICS          16528\n",
            "ENTERTAINMENT      6204\n",
            "WORLD NEWS         3297\n",
            "QUEER VOICES       1917\n",
            "COMEDY             1811\n",
            "HEALTHY LIVING     1446\n",
            "BLACK VOICES       1422\n",
            "U.S. NEWS          1377\n",
            "PARENTS            1261\n",
            "WOMEN              1243\n",
            "THE WORLDPOST      1081\n",
            "MEDIA              1054\n",
            "SPORTS              957\n",
            "WEIRD NEWS          793\n",
            "CRIME               779\n",
            "GREEN               569\n",
            "STYLE               563\n",
            "ARTS & CULTURE      536\n",
            "BUSINESS            535\n",
            "TASTE               530\n",
            "IMPACT              416\n",
            "RELIGION            409\n",
            "LATINO VOICES       385\n",
            "TRAVEL              326\n",
            "EDUCATION           269\n",
            "TECH                204\n",
            "STYLE & BEAUTY      165\n",
            "SCIENCE             162\n",
            "HOME & LIVING       125\n",
            "ENVIRONMENT         121\n",
            "WELLNESS            118\n",
            "FOOD & DRINK        114\n",
            "PARENTING           114\n",
            "COLLEGE              57\n",
            "MONEY                49\n",
            "CULTURE & ARTS       44\n",
            "GOOD NEWS            24\n",
            "WORLDPOST             3\n",
            "WEDDINGS              2\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load the original dataset\n",
        "file_path = \"News_Category_Dataset_v3.json\"  # Update with actual path\n",
        "df = pd.read_json(file_path, lines=True)\n",
        "\n",
        "# Count rows and columns of the original dataset\n",
        "print(f\"Number of rows in original dataset: {df.shape[0]}\")\n",
        "print(f\"Number of columns in original dataset: {df.shape[1]}\")\n",
        "\n",
        "# Display the head of the original dataset\n",
        "display(df.head())\n",
        "\n",
        "# Remove white space or empty strings and make them null\n",
        "df = df.applymap(lambda x: None if isinstance(x, str) and x.strip() == '' else x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "# Count and identify null values in the original dataset\n",
        "null_counts = df.isnull().sum()\n",
        "print(f\"Null values in each column:\\n{null_counts}\")\n",
        "\n",
        "# Count duplicated rows in the original dataset\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(f\"Number of duplicated rows: {duplicate_count}\")\n",
        "\n",
        "# Drop rows with null values in 'headline' or 'short_description' from the original dataset\n",
        "df = df.dropna(subset=['headline', 'short_description'])\n",
        "\n",
        "# Drop all duplicated rows from the original dataset\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Retain only rows with dates from 2017 to 2022\n",
        "df = df[df['date'].dt.year.isin(range(2017, 2023))]\n",
        "\n",
        "# Count rows and columns after cleaning the original dataset\n",
        "print(f\"Number of rows after cleaning: {df.shape[0]}\")\n",
        "print(f\"Number of columns after cleaning: {df.shape[1]}\")\n",
        "\n",
        "# List the unique categories\n",
        "categories = df['category'].unique()\n",
        "print(categories)\n",
        "\n",
        "# Print the number of rows for each category\n",
        "category_counts = df['category'].value_counts()\n",
        "print(category_counts)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
